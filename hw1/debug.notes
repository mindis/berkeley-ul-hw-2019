Note to change factorised / full in your model change get_pixelcnn_mask() default kwarg in pixelCNN.py

PixelCNN
    Factorised
        works on debug and few (single)
        Main 4k iter, loss bit jumpy, try lower LR? samples getting there but poor
    Full
        works on debug, bit dubious but seems to learn something on few (single)
        Main w/ 4,000 iterations -
2* try 4k iter on full

PixelCNN-MADE
    Factorised
        works on debug and few (single)
        main 4k: loss improves but doesn't get past 0.33, samples poor
    Full
        main 4k: loss improves but doesn't get past 0.33, samples poor but do seem to be getting there

PixelCNN-DS
on main, 10e-4, lowest loss: 0.134 in 2,500 iterations, samples good quality
why is this lower than they report?
    x DONE try batching that shuffles then goes through all examples
    performs better on new batching, more monotonic decrease of loss, samples are good
10e-3 on theirs
    seems noisy and jumpy, samples quite poor
* compare and debug to yours
3* swap in parts eg. masking function

Swapping in masking functions
    Their masking function in my model (pixelcnn) gets to 0.133 loss, but samples are poor
        perhaps its my mask AND model? my sampling?
    My masking in their model, seems to improve then at 500 iter at 0.33 loss it blows up to 1+ loss, samples are poor

Next:
    try their mask and sample with my model