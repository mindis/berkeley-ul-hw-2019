Note to change factorised / full in your model change get_pixelcnn_mask() default kwarg in pixelCNN.py

PixelCNN
    Factorised
        works on debug and few (single)
        Main 4k iter, loss bit jumpy, try lower LR? samples getting there but poor
    Full
        works on debug, bit dubious but seems to learn something on few (single)
        Main w/ 4,000 iterations -
2* try 4k iter on full

PixelCNN-MADE
    Factorised
        works on debug and few (single)
        main 4k: loss improves but doesn't get past 0.33, samples poor
    Full
        main 4k: loss improves but doesn't get past 0.33, samples poor but do seem to be getting there

PixelCNN-DS
on main, 10e-4, lowest loss: 0.134 in 2,500 iterations, samples good quality
why is this lower than they report?
    x DONE try batching that shuffles then goes through all examples
    performs better on new batching, more monotonic decrease of loss, samples are good
10e-3 on theirs
    seems noisy and jumpy, samples quite poor
* compare and debug to yours
3* swap in parts eg. masking function

Swapping in masking functions
    Their masking function in my model (pixelcnn) gets to 0.133 loss, but samples are poor
        -> perhaps its my mask AND model? my sampling?
    My masking in their model, seems to improve then at 500 iter at 0.33 loss it blows up to 1+ loss for the rest
    samples are v poor
        -> my masking is wrong?
    Their mask and samples in my model: loss to 0.18, samples are better than with my sampling, but still not as
    good as their full setup - has the texture but not the shape
        -> look at sampling, but have also changed softmax now

13/01
Have changed my architecture to match the paper and DS code (removed one of the 1x1 output conv layers)
Have read through the code and mostly seems similar to mine, have made note below of a few things to check:
    * compare the masking
    * any difference in the conv I use vs DS?
TFP and NP sampling is empirically very similar (see PixelCNN_DS.compare_sampling)

Next: check 13/01 todos
